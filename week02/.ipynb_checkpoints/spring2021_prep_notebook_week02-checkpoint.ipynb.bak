{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Datatypes: Images (raster & vector), Tabular data\n",
    "\n",
    "1. Images\n",
    "   1. Raster images: Quantifying the badness of Stitch with math!\n",
    "   1. EXTRA: Vector images: using Python to make diagrams\n",
    "1. Tabular data\n",
    "   1. EXTRA: with Python's `csv` library\n",
    "   1. with Pandas (https://pandas.pydata.org/)\n",
    "   1. EXTRA: with NumPy (https://numpy.org/) (probably not time though... maybe next time?)\n",
    "   \n",
    "Note: items labeled with an \"EXTRA\" means that we are unlikely to get to them in class, but they are here as additional info for you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start this notebook by importing a few things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams[\"font.family\"] = \"sans-serif\" # note, could also use like \"sans-serif\" others, just google\n",
    "\n",
    "# lets also import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%matplotlib inline` is needed to make plots appear \"inline\", i.e. in this notebook and is not needed in ALL installs, but we put it in to be on the safe side!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Images\n",
    "\n",
    "Depending on interpretation images can be considered as spatial or field data data (raster images), or tree/hierarchical data (vector images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.A Raster images\n",
    "\n",
    "We'll explore how to manipulate raster images -- where you are given color information at each pixel (x,y) coordinates.\n",
    "\n",
    "Link to image: https://uiuc-ischool-dataviz.github.io/spring2019online/week01/images/stitch_reworked.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mainpulate images, we'll import a function from the `PILLOW` library like last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image # this imports *only* the Image function from the PIL module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll import my image.  This assumes you have downloaded the image from our class website and have saved it somewhere where you remember the path.  I'm on a Mac, so mine defaults to the downloads folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(\"/Users/jnaiman/Downloads/stitch_reworked.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a quick look at this image inline (i.e. inside this Jupyter notebook) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi Stitch! :D\n",
    "\n",
    "We can also transform this image into data using NumPy like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data = np.array(im)\n",
    "im_data # I can just put this line right here at the end and it will print out this data \"inline\" as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check out some features of this dataset.  For example, what is the shape of this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 483x430 image with 4 color channels: (R=Red, G=Green, B=Blue, A=Alpha), where here \"Alpha\" means opacity.\n",
    "\n",
    "One represenation of RGB color combinations can be seen in a typical \"color wheel\":\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/b7/45/3a/b7453aedcbd060c8b842d85f27c083fb.jpg\" width=\"400px\">\n",
    "\n",
    "What are the unique numbers in this dataset? (i.e. this dataset's values w/o any repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(im_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASIDE:\n",
    "The above lists the unique numbers in this dataset.  If we wanted to check color by color? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_labels = ['R', 'G', 'B', 'A']\n",
    "for i in range(im_data.shape[2]): # this loops over the last entry of the shape array, so the #4\n",
    "    print('channel=', channel_labels[i], \n",
    "          'unique values=', np.unique( im_data[:,:,i] ) ) # print the unique elements in each channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us some interesting things!  Unless there are weird combinations, it looks like we have only 3 colors here.  We also only have 2 opacity channels -- either a pixel is opaque (255) or completely invisible (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check the uniqe colors by once again apply `np.unique` but using the \"axis\" argument to tell it what axis to look down.  This is a bit of Python \"magic\" so feel free to just take my word for it right now, or you can read more details here: https://stackoverflow.com/questions/24780697/numpy-unique-list-of-colors-in-the-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END ASIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how many unique RGBA combos, we can make use of the `np.unique` function.  Let's try using it the naive way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(im_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll, this isn't quite what we want -- we want a list of the RGBA combs, not all the unique numbers in the array as a whole.  To do this, we have to mess with the shape of the array we give `np.unique`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's line up this array instead of as x/y pixels as a list of pixels's RGBA colors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data.reshape(-1, im_data.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply `np.unique` to this reshaped array and specify the specifc axis (the first or 0th axis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(im_data.reshape(-1, im_data.shape[2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also display this image again, but since we have the data, we can use `matplotlib` to plot which will give us nice things like axis marks.  If we recall what we did last time with `fig, ax = plt.subplots...`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10)) # generate a \"fig\" and \"ax\" object\n",
    "\n",
    "ax.imshow(im_data) # use imshow function with \"ax\" object\n",
    "\n",
    "plt.show() # this gets rid of the print memory address thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, its a bit hard to see that there is white in the interior part of Stitch and then it's transparent outside.  We can modify our plot to show this, by making a gray background.  We can \"cheat\" into this gray background by multiplying our data with 0 and then giving it an overall \"gray\" RGBA sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data*0 + 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10)) # generate a \"fig\" and \"ax\" object\n",
    "\n",
    "ax.imshow(im_data*0+125) # this first plots a gray image underneath (all RGBA components = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10)) # generate a \"fig\" and \"ax\" object\n",
    "\n",
    "ax.imshow(im_data*0+125) # this first plots a gray image underneath (all RGBA components = 0.5)\n",
    "# Note: you can also specify colors in RGB space in the range 0.0-1.0 like we are doing here\n",
    "#       instead of 0-255 like we did above!\n",
    "\n",
    "ax.imshow(im_data) # then we plot our Stitch image over the top\n",
    "\n",
    "plt.show() # this gets rid of the print memory address thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we recall from the lecture, we talked a bit about how to use this visualization to figure out how to quantify the goodness or badness of Stitch.  Let's play with this idea a bit more now.\n",
    "\n",
    "Let's start by counting up all the pixels that are \"good\" in Stitch.  If we see our image above, this is denoted by the white parts of the head an ears.  \n",
    "\n",
    "**NOTE: this is an example of *filtering* our data!**\n",
    "\n",
    "In color space, white is denoted by (255, 255, 255, 255) so we will create a filtering \"mask\" for these values by making sure all color channels have the value of 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can make a boolean mask that only looks for when the R channel, the first in the RGBA channels, is at the maximum value = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reds_good_mask = im_data[:,:,0] == 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reds_good_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its mostly false because most of the image does NOT have a 255 red channel.  But we can also see which parts of the image are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data[reds_good_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(im_data[reds_good_mask].reshape(-1, im_data.shape[2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this is, in theory ONLY looking for pixels that have 255 in the red channel, and we are lucky in this case that this is only associated with one color -- the color white.  But, to be sure, we really want to make a check for ALL of the RGBA channels and make a combined mask for all of them.  With boolean masks this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reds_good_mask = im_data[:,:,0] == 255\n",
    "greens_good_mask = im_data[:,:,1] == 255\n",
    "blues_good_mask = im_data[:,:,2] == 255\n",
    "alphas_good_mask = im_data[:,:,3] == 255\n",
    "\n",
    "# pixel_mask_good is the combined boolean mask that will check for ALL conditions\n",
    "pixel_mask_good = reds_good_mask & greens_good_mask & blues_good_mask & alphas_good_mask\n",
    "# Note the \"\\\" is a line continuation character --> make sure you don't have anything, even a space after it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using this mask, let's count up the number of \"good\" pixels.  \n",
    "\n",
    "We do this by first selecting out only the good pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_pixels = im_data[pixel_mask_good]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we find out the length of this array which is simply the total number of \"good\" pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngood = len(good_pixels)\n",
    "ngood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even plot this part of our dataset by creating a masked Stitch image that will just take this \"good\" part out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data_masked_good = im_data.copy() # first we make a copy of our original dataset to modify\n",
    "im_data_masked_good[~pixel_mask_good] = 0 # then we set everything that is *NOT* a good pixel to 0 so it will show up gray\n",
    "# Note here the \"~\" is the opposite mask of our good pixel mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10)) # generate a \"fig\" and \"ax\" object\n",
    "\n",
    "ax.imshow(im_data*0.0+0.5) # plot gray background as before\n",
    "\n",
    "ax.imshow(im_data_masked_good) # then we plot our Stitch image over the top\n",
    "\n",
    "plt.show() # this gets rid of the print memory address thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing for the \"bad\" pixels.  This is the color RGBA combo of: (126, 22, 33, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_mask_bad = (im_data[:,:,0] == 126) & \\\n",
    "                  (im_data[:,:,1] == 22) & \\\n",
    "                  (im_data[:,:,2] == 33) & \\\n",
    "                  (im_data[:,:,3] == 255)\n",
    "# Note the \"\\\" is a line continuation character --> make sure you don't have anything, even a space after it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbad = len(im_data[pixel_mask_bad])\n",
    "nbad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data_masked_bad = im_data.copy() # first we make a copy of our original dataset to modify\n",
    "im_data_masked_bad[~pixel_mask_bad] = 0 # then we set everything that is *NOT* a good pixel to 0 so it will show up gray\n",
    "# Note here the \"~\" is the opposite mask of our good pixel mask\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10)) # generate a \"fig\" and \"ax\" object\n",
    "\n",
    "ax.imshow(im_data*0.0+0.5) # plot gray background as before\n",
    "\n",
    "ax.imshow(im_data_masked_bad) # then we plot our Stitch image over the top\n",
    "\n",
    "plt.show() # this gets rid of the print memory address thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the goodness/badness ratio as their respective numbers divided by the total number of interior pixels: \n",
    "\n",
    "$\\rm{goodness \\, \\%} = \\frac{ngood}{ngood+nbad}$\n",
    "\n",
    "$\\rm{badness \\, \\%} = \\frac{nbad}{ngood+nbad}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = ngood + nbad\n",
    "badness = nbad / total\n",
    "goodness = ngood/  total\n",
    "print(badness, goodness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks like about 77% bad and 23% good, by volume.  Does that match up with what you'd think from looking at the above figure?\n",
    "\n",
    "We can now plot the goodness and badness levels with a little bar plot that may show these levels a bit more accurately.  We'll also add a little legend to show what is \"goodness\" and \"badness\" colors.\n",
    "\n",
    "Note, there is a nice diagram of the named colors in Python below:\n",
    "\n",
    "<img src=\"https://matplotlib.org/3.1.0/_images/sphx_glr_named_colors_003.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "ax.bar([1], badness, [0.5], color='maroon', label=\"badness\") # this just plots a bar centered at 1 with a width of 0.5\n",
    "\n",
    "ax.bar([1], goodness, [0.5], color=\"steelblue\", \n",
    "       bottom=badness, label=\"goodness\") # this plots a bar *on top* of the badness bar\n",
    "\n",
    "ax.set_xlim(0.0, 2.0) # to center around our bar\n",
    "\n",
    "# since our x-axis are meaningless, we want to \"hide\" them (see week01's notebook):\n",
    "ax.xaxis.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just counted pixes from our figure above? Looks like good changes to badness at ~150, image top is at ~75 pixels image bottom is at ~425 pixels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remind ourselves a bit of what this image looks like\n",
    "fig,ax = plt.subplots(figsize=(5,5))\n",
    "ax.imshow(im)\n",
    "\n",
    "ax.plot([0,450], [150, 150]) # approximate badness line\n",
    "ax.plot([0,450], [75, 75]) # approximate top line\n",
    "ax.plot([0,450], [425, 425]) # approximate bottom line\n",
    "\n",
    "ax.set_xlim(0,450)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so:\n",
    "goodness_apparent = (75-150)/(75-425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is badness, apparent\n",
    "1.0-goodness_apparent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few more visualizations of this dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1: A pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.pie([badness,goodness]) # can also do a pie chart if we want I suppose :D\n",
    "# note: this uses wedges!!\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2: Side-by-side histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "# we'll turn these into arrays to make our lives easier down the road\n",
    "labels = np.array(['badness', 'goodness'])\n",
    "values = np.array([badness, goodness])\n",
    "colors = np.array(['maroon', 'steelblue'])\n",
    "\n",
    "myBarChart = ax.bar(labels, values) \n",
    "\n",
    "# set colors for each bar individually\n",
    "for i in range(len(myBarChart)):\n",
    "    myBarChart[i].set_color(colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the RGBA color values for the \"goodness\" and \"badness\" we can also plot these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "labels = np.array(['badness', 'goodness'])\n",
    "values = np.array([badness, goodness])\n",
    "colors = np.array([(126, 22, 33, 255), (255, 255, 255, 255)])\n",
    "\n",
    "myBarChart = ax.bar(labels, values) \n",
    "\n",
    "# set colors for each bar individually\n",
    "for i in range(len(myBarChart)):\n",
    "    myBarChart[i].set_color( colors[i]/255 )\n",
    "    myBarChart[i].set_edgecolor('black') # because one of our colors is white\n",
    "    myBarChart[i].set_linewidth(2) # so we can see the outlines clearly\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Bar charts of all colors\n",
    "\n",
    "Looking at the number of unique colors in this image I can see that there are in fact 4 (we only used 2 to plot \"goodness\" and \"badness\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(im_data.reshape(-1, im_data.shape[2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try plotting all of the colors combining what we have used in this image manipulation lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_pixels_of_a_color = []\n",
    "color_labels = []\n",
    "colors = []\n",
    "for icolor,rgba in enumerate(np.unique(im_data.reshape(-1, im_data.shape[2]), axis=0)):\n",
    "    #print(icolor, rgba)\n",
    "    \n",
    "    # mask each channel\n",
    "    reds_mask = im_data[:,:,0] == rgba[0]\n",
    "    greens_mask = im_data[:,:,1] == rgba[1]\n",
    "    blues_mask = im_data[:,:,2] == rgba[2]\n",
    "    alphas_mask = im_data[:,:,3] == rgba[3]\n",
    "\n",
    "    # combined mask\n",
    "    pixel_mask = reds_mask & greens_mask & blues_mask & alphas_mask\n",
    "    \n",
    "    # grab number of pixels\n",
    "    this_color_pixels = im_data[pixel_mask]\n",
    "    number_of_pixels_of_a_color.append(len(this_color_pixels))\n",
    "    # this could be done better...\n",
    "    color_labels.append( 'Color #' + str(icolor) )\n",
    "    \n",
    "    colors.append( rgba/255 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors # again, these have to be re-scaled to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "myBarChart = ax.bar(color_labels, number_of_pixels_of_a_color) \n",
    "# set colors for each bar individually\n",
    "for i in range(len(myBarChart)):\n",
    "    myBarChart[i].set_color(colors[i])\n",
    "    myBarChart[i].set_edgecolor('black') # because one of our colors is white\n",
    "    myBarChart[i].set_linewidth(2) # so we can see the outlines clearly\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** the above histograms are some examples of *data mutations* or *mutating our data*.\n",
    "\n",
    "#### Bonus: Shuffling Stitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_shuffle = im_data.copy()\n",
    "\n",
    "# shuffle horizontal\n",
    "sub = im_data[0:50, :, :].copy()\n",
    "im_shuffle[0:50,:,:] = im_data[150:200,:,:]\n",
    "im_shuffle[150:200,:,:] = sub\n",
    "\n",
    "sub = im_data[400:450, :, :].copy()\n",
    "im_shuffle[300:350,:,:] = im_data[400:450,:,:]\n",
    "im_shuffle[400:450,:,:] = sub\n",
    "\n",
    "# shuffle vertical\n",
    "sub = im_data[:, 0:50, :].copy()\n",
    "im_shuffle[:, 0:50,:] = im_data[:, 150:200,:]\n",
    "im_shuffle[:,150:200,:] = sub\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(im_shuffle)\n",
    "\n",
    "# taking of axis and \"tight layout\"\n",
    "ax.xaxis.set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.spines['right'].set_visible(False) # takes off right y-axis\n",
    "ax.spines['left'].set_visible(False) # takes off left y-axis\n",
    "ax.spines['top'].set_visible(False) # takes off the top x-axis\n",
    "ax.spines['bottom'].set_visible(False) # takes off the bottom x-axis\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show() # show\n",
    "\n",
    "fig.savefig('./images/shuffled_stitch.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA: 1.B Vector images\n",
    "\n",
    "Vector images are constructed with a set of \"instructions\" rather than color values at (x,y) coordinates.  This can make their construction adn manipulation easier to deal with since you can tweak these instructions and change the look of the diagram.  In contrast, to change elements of a raster image, you have to make changes pixel-by-pixel.\n",
    "\n",
    "**NOTE:** since we will mostly be dealing with raster images in this course, we may skip this portion in class if we are short on time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-do that diagram of the angular distribution of human vision we had in the slides from last lecture, in particular, the FOV image.\n",
    "\n",
    "<img src=\"https://uiuc-ischool-dataviz.github.io/spring2020/week01/images/fov.png\" width='600px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first choose an edge color for our diagrams.  It looks like we are using black to draw lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgecolor = 'black'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also pick the colors for the large wedge which looks sort of blueish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facecolor_totalFOV = \"steelblue\" # check out list of colors above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the colors of the binocular part of the FOV diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facecolor_bincFOV = \"darkorange\" # check out list of colors above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only color left looks to be the colors of the arrows which are grayish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facecolor_arrow = \"silver\" # gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make use of some vector-drawing capabilities of `matplotlib`.  First we make a blue wedge that shows the full field of view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFOV = matplotlib.patches.Wedge([0.0, 0.0], 1.0, 90 - (210/2.0), 90 + (210/2.0), # span of the wedge\n",
    "                                    lw=2.0, \n",
    "                                    facecolor=facecolor_totalFOV, \n",
    "                                    edgecolor=edgecolor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build up diagrams by adding \"patches\" one by one, first let's try making a plot of just this FOV wedge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax.add_patch(totalFOV)\n",
    "\n",
    "ax.set_xlim(-1.25, 1.25)\n",
    "ax.set_ylim(-0.5, 1.25)\n",
    "\n",
    "# This below takes off the tick marks and axis labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add in the Binocular part and replot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFOV = matplotlib.patches.Wedge([0.0, 0.0], 1.0, 90 - (210/2.0), 90 + (210/2.0), # span of the wedge\n",
    "                                    lw=2.0, \n",
    "                                    facecolor=facecolor_totalFOV, \n",
    "                                    edgecolor=edgecolor)\n",
    "\n",
    "binoc = matplotlib.patches.Wedge([0.0, 0.0], 1.0, 90 - (114/2.0), 90 + (114/2.0), \n",
    "                                 width=0.25, # so that it doesn't overlap totally with total FOV\n",
    "                                 lw=2.0, \n",
    "                                 facecolor=facecolor_bincFOV, edgecolor=edgecolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax.add_patch(totalFOV)\n",
    "ax.add_patch(binoc)\n",
    "\n",
    "ax.set_xlim(-1.25, 1.25)\n",
    "ax.set_ylim(-0.5, 1.25)\n",
    "\n",
    "# This below takes off the tick marks and axis labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... now add in the arrows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFOV = matplotlib.patches.Wedge([0.0, 0.0], 1.0, 90 - (210/2.0), 90 + (210/2.0), # span of the wedge\n",
    "                                    lw=2.0, \n",
    "                                    facecolor=facecolor_totalFOV, \n",
    "                                    edgecolor=edgecolor)\n",
    "\n",
    "binoc = matplotlib.patches.Wedge([0.0, 0.0], 1.0, 90 - (114/2.0), 90 + (114/2.0), \n",
    "                                 width=0.25, # so that it doesn't overlap totally with total FOV\n",
    "                                 lw=2.0, \n",
    "                                 facecolor=facecolor_bincFOV, edgecolor=edgecolor)\n",
    "\n",
    "arrow = matplotlib.patches.Arrow(-1.10, 0.0, 0.0, 0.75, \n",
    "                                 width=0.25, edgecolor=edgecolor, \n",
    "                                 facecolor=facecolor_arrow)#, label=\"forward\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax.add_patch(totalFOV)\n",
    "ax.add_patch(binoc)\n",
    "ax.add_patch(arrow)\n",
    "\n",
    "ax.set_xlim(-1.25, 1.25)\n",
    "ax.set_ylim(-0.5, 1.25)\n",
    "\n",
    "# This below takes off the tick marks and axis labels\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's re-do the whole thing, but with text this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFOV = matplotlib.patches.Wedge([0.0, 0.0], 1.0, 90 - (210/2.0), 90 + (210/2.0), # span of the wedge\n",
    "                                    lw=2.0, \n",
    "                                    facecolor=facecolor_totalFOV, \n",
    "                                    edgecolor=edgecolor)\n",
    "\n",
    "binoc = matplotlib.patches.Wedge([0.0, 0.0], 1.0, 90 - (114/2.0), 90 + (114/2.0), \n",
    "                                 width=0.25, # so that it doesn't overlap totally with total FOV\n",
    "                                 lw=2.0, \n",
    "                                 facecolor=facecolor_bincFOV, edgecolor=edgecolor)\n",
    "\n",
    "arrow = matplotlib.patches.Arrow(-1.10, 0.0, 0.0, 0.75, \n",
    "                                 width=0.25, edgecolor=edgecolor, \n",
    "                                 facecolor=facecolor_arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7), dpi=300)\n",
    "\n",
    "ax.add_patch(totalFOV)\n",
    "ax.add_patch(binoc)\n",
    "ax.add_patch(arrow)\n",
    "\n",
    "ax.set_xlim(-1.25, 1.25)\n",
    "ax.set_ylim(-0.5, 1.25)\n",
    "\n",
    "# Finally, lets overplot the arrow's notatoin\n",
    "plt.text(-1.22, 0.25, \"Forward\", rotation=90, fontsize=\"xx-large\")\n",
    "\n",
    "\n",
    "# lets also add a legend to remind us what is what\n",
    "ax.legend([totalFOV, binoc], [\"Total FOV\", \"Binocular FOV\"], fontsize=\"x-large\")\n",
    "\n",
    "\n",
    "# disappear the axis & ticks\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save this image in a vector format to use in vector applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('images/wedges_saved.svg') # this saves in a folder named \"images\" in the present \n",
    "#                                         directory - feel free to change as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take away\n",
    "* so, that was a lot of effort (maybe) to make a diagram, *but* we can now go back and change things very easily \n",
    "* for example we can change all the colors **do this**, or we can change the size of the wedge\n",
    "* the take away is that Python not only makes graphs, but it can also be used to make diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tabular Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try making some histograms from tabular data, in this case a CSV file.\n",
    "\n",
    "Make sure you have the building inventory downloaded from the class website! https://uiuc-ischool-dataviz.github.io/spring2019online/week02/building_inventory.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA: 2.A: Python's csv library\n",
    "\n",
    "We'll use the `csv` library within Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supply the full path to the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"/Users/jnaiman/Downloads/building_inventory.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are just going to read in our data. We can see its sort of in a weird format that isn't terribly intuative to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.seek(0) # start at the top of the file\n",
    "for record in csv.reader(f):\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try formatting this data ourselves.  Let's fill up a dictonary with each column and then add data into it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.seek(0)\n",
    "reader = csv.reader(f)\n",
    "header = next(reader) # this is just so that we grab only the data columns\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use these data headers to fill in a dictionary with data entries.\n",
    "\n",
    "Refer to IS452's intro to dictionaries for reference: https://github.com/jnaiman/IS-452AO-Fall2019/blob/master/Lectures/Week-09-Dictionaries.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {} # empty dictonary\n",
    "for col in header: # for every column name (key in dictionary) in header\n",
    "    data[col] = [] # add a value to this key and give make it an empty list\n",
    "data # now we have an empty dictonary with named entries ready to be filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill the dictionary we are going to use the function `zip`.\n",
    "\n",
    "Here is a little example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"hi\", \"there\", \"my\", \"friends\"]\n",
    "b = [9, 4, 1, 9]\n",
    "for word, num in zip(a, b):\n",
    "    print(word, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of if kind of like \"enumerate\" that we used above, but its iterating over 2 lists here instead of a number and a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `zip` to fill up our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, a call like before\n",
    "f.seek(0)\n",
    "reader = csv.reader(f)\n",
    "header = next(reader)\n",
    "\n",
    "# repeat our creation of our data dictionary & initialize to empty lists\n",
    "data = {}\n",
    "# fill column names as dictionary headings\n",
    "for col in header:\n",
    "    data[col] = []\n",
    "    \n",
    "# finally, fill lists within headers\n",
    "for row in reader:\n",
    "    for col, val in zip(header, row):\n",
    "        data[col].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call our data dictionary like we would any other dictionary, by giving it a `key` and seeing what `values` come with that key.  For example, what values are associated with the `Zip code` key?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Zip code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Zip code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.unique(data['Zip code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Agency Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use keys() to list our dictionary names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making plots using our `data` dictionary\n",
    "\n",
    "If we want to aggretate our data, we can use something like the `collections` module and the `Counter` object (see IS452 Dictionaries week again for a reminder!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, here we can create a counter for how many entries have particular agency names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counter = collections.Counter(data['Agency Name'])\n",
    "agency_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these counter objects to make plots like before.  Let's start with a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.bar(agency_counter.keys(), agency_counter.values())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow is it hard to read those labels!  Let's try rotating them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "ax.bar(agency_counter.keys(), agency_counter.values())\n",
    "fig.autofmt_xdate(rotation=90)\n",
    "\n",
    "# or:\n",
    "#plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is starting to look pretty cool.  What about if we just want to plot the top 10 though since it looks like most of the interesting stuff happens there!\n",
    "\n",
    "If we recall, we can do this with a counter object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counter.most_common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counter_top_10 = agency_counter.most_common(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counter_top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above is now a list, not a dictionary so we have to reformat a bit if we want to plot things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counter_top_10[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_counter_top_10[0][0], agency_counter_top_10[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agency_name_top_10 = []; count = []\n",
    "for ac in agency_counter_top_10:\n",
    "    agency_name_top_10.append(ac[0])\n",
    "    count.append(ac[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "ax.bar(agency_name_top_10, count)\n",
    "fig.autofmt_xdate(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.B Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a lot of these things with the `pandas` library.\n",
    "\n",
    "(This is something you can pip or anaconda install if you need to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings = pd.read_csv('/Users/jnaiman/Downloads/building_inventory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings\n",
    "# formatting here is sort of nice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas comes with a lot of nice built in functions like for example, we can easily count how many entries there are in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many entries are there? as an iterable\n",
    "buildings.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out slices of our dataset by index like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.iloc[0:3] # subset by index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build up querys, like grab the agency name of the 100-110'th entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.iloc[100:110][\"Agency Name\"] # grab 1-10 entries, and print out the Agency names of those entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use NumPy-like functions, like counting how many unique agency names are in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"Agency Name\"].nunique() # how many unique agencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this with categorical data, like the building status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"Bldg Status\"].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are used to R at all, the `describe` function is sort of like \"summary\" function, and basically giving some summary statistics for the numerical data in our dataset.\n",
    "\n",
    "Note that some of these statistics don't make sense, for example the \"mean\" zip code doesn't make physical sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `.iloc` before, we can filter our data by using `.loc` which allows us to pass filtering information.\n",
    "\n",
    "For example, let's only look at buildings that have zero square footage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.loc[buildings[\"Square Footage\"] == 0] # boolean operation inside means zero square footage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter for ongoing construction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.loc[buildings[\"Bldg Status\"] == \"In Progress\"] # who is being built now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a lot of useful functions associated with our datasets, for example, we can plot the distribution of square footage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"Square Footage\"].plot() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we do with this plot?  What are our options?\n",
    "\n",
    "Check out: https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.plot.html\n",
    "\n",
    "While the above was a \"quick and dirty\" plot, we can do fancier things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.plot(x = \"Address\", y=\"Square Footage\", figsize=(20,6), rot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use Pandas to generate the plot and then give you back the matplotlib `ax` objects we've been dealing with before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = buildings.plot(x = \"Year Acquired\", y=\"Square Footage\", figsize=(20,6), rot=90, kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = buildings.plot(x = \"Year Acquired\", y=\"Square Footage\", figsize=(20,6), rot=90, kind='scatter')\n",
    "ax.set_xlim(1750, 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some useful sorting functions within Pandas.  The `groupby` function can seem a little nebulous, but its a way to sort of \"re-index\" our datasets.  Here we'll re-group our data by the building's status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.groupby(\"Bldg Status\") # this doesn't do anything until you call it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now actually do something with this object, here, just print out - you can see \"abandon\" is at the top - so i first lists off all of the abandoned buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grouped in buildings.groupby(\"Bldg Status\"):\n",
    "    print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for status, df in buildings.groupby(\"Bldg Status\"):\n",
    "    print(status, df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply NumPy-like functions, for example `max`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings[\"Square Footage\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several differnet options for *how* to read data with Pandas.  For example, we can tell Pandas what to do with empty entries, i.e. ones with a `NaN` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.read_csv(\"/Users/jnaiman/Downloads/building_inventory.csv\",\n",
    "           na_values = {'Square Footage': 0,\n",
    "                       'Year Acquired': 0,\n",
    "                       'Year Constructed': 0}) \n",
    "# specify what to do with incomplete entries, here this just says if any of these columns have a value 0, treat\n",
    "#  as a NaN or not-a-number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"Square Footage\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"Year Constructed\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[\"Year Acquired\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.loc[b[\"Year Acquired\"] < 1800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also mutate Pandas dataframes into new data with operations like sorting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = b.sort_values(\"Year Constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2.iloc[0] # this gives the oldest building - the one that was constructed in 1753"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build up Pandas commands to get new sorts of aggregated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.groupby(\"Year Acquired\")[\"Square Footage\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use that to make different plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = b.groupby(\"Year Acquired\")[\"Square Footage\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aggregated_data.index, aggregated_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use pandas plots to do this as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = b.groupby(\"Year Acquired\")[\"Square Footage\"].sum()\n",
    "aggregated_data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aggregate in a bunch of different ways!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data_average = b.groupby(\"Year Acquired\")[\"Square Footage\"].mean()\n",
    "aggregated_data_average.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go bananas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.loc[b[\"Agency Name\"] == \"University of Illinois\"].groupby(\"Year Acquired\")[\"Square Footage\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASIDE: Python tips and tricks! We won't go through this in lecture but it's here if you want it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We've been playing around with a few complex things in Python, but lets take a step back for a moment and delve into how Python deals with data in a bit more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a\n",
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a gander at a\n",
    "a\n",
    "# hey look a is an empty list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can mix types in our lists\n",
    "a = [1, 2, \"hey\"]\n",
    "# here we have a few integers and a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at a again\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also, for our general purposes, we can call a string with a single or double quotes\n",
    "'hey' == \"hey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also easily add to our list with the append statement\n",
    "a.append(\"there\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an item at an index, & removes item, default is the last item\n",
    "a.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now a is back to what we had before\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also grab elements of a by their indicies\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that indexing starts from 0 in python\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the -# can be used to grab starting from the last element of the list\n",
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the colon means \"all the things\"\n",
    "a[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also take subsets easily, for example, ignorning the first element of a\n",
    "# this is a way to filter data\n",
    "a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also take all but the last eleement\n",
    "a[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also combine these two things to grab from the first to the 2nd to last element\n",
    "# in this case, the one element\n",
    "a[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are also some nice string manipulations we can do\n",
    "#  like splitting a string into a list object\n",
    "a = \"this is a much longer list, where i have taken a sentence and split it based on the spaces\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can grab every other element in the list\n",
    "a[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also reorder this list back-to-front\n",
    "a[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also update individual strings in this list\n",
    "a[3] = 'sorta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets look quickly at some funny things about strings in Python\n",
    "name = \"jill\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will produce an error\n",
    "name[0] = 'J'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to use something like replace\n",
    "name.replace(\"j\",\"J\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python also has stuff called dictionaries\n",
    "d = {'bevier': 'building', 'green' : 'road', 'champaign': 'city'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the \"champaign\" entry is of type \"city\"\n",
    "d['champaign']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its super easy to add to dictionaries, here we add an empty list\n",
    "d['mylist'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can add to this list in the usual way - with the above \"append\" function we used before\n",
    "d['mylist'].append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are these other cool objects called \"sets\"\n",
    "myset = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check out some operations with sets, for example some movies I like\n",
    "jill_movies = set(['last jedi', 'girls trip', 'frozen'])\n",
    "# lets say we have another person named bob an these are the movies he likes\n",
    "bob_movies = set(['last jedi', 'other movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jill_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create a set that is made up of my movies, but without those movies that appear in bob's movies list\n",
    "jill_movies - bob_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jill_movies[0] # note we can't index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can take the union of sets\n",
    "jill_movies.union(bob_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some final string manipulation, we can use a thing called enumerate \n",
    "# to both count in a for loop and use an element of our list directly\n",
    "for i, word in enumerate(reversed(a)):\n",
    "    print(i, word.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue and break are flow control statements\n",
    "for i, word in enumerate(sorted(a)):\n",
    "    if word == \"and\":\n",
    "        continue\n",
    "    if word == \"it\":\n",
    "        break\n",
    "    print(i, word.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also, we can use the \"?\" to figure out things we don't know, for example the reader\n",
    "#  function from  the csv library\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.reader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
